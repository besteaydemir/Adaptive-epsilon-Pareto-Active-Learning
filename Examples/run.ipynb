{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import numpy as np\n",
    "import gpflow as gpf\n",
    "\n",
    "from AdaptiveEpsilonPAL import AdaptiveEpsilonPAL\n",
    "from OptimizationProblem import OptimizationProblem\n",
    "from GaussianProcessModel import GaussianProcessModel\n",
    "from Hypercube import Hypercube\n",
    "\n",
    "from utils_plot import plot_func_list, plot_pareto_front\n",
    "from utils import printl\n",
    "\n",
    "from paretoset import paretoset\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import gpflow as gpf\n",
    "from sklearn import preprocessing\n",
    "from AdaptiveEpsilonPAL import AdaptiveEpsilonPAL\n",
    "from OptimizationProblem import OptimizationProblem\n",
    "from GaussianProcessModel import GaussianProcessModel\n",
    "from Hypercube import Hypercube\n",
    "from utils import printl\n",
    "\n",
    "from utils_plot import plot_func_list, plot_pareto_front\n",
    "\n",
    "from paretoset import paretoset\n",
    "import pandas as pd\n",
    "# Set seed for reproducibility\n",
    "    np.random.seed(10)\n",
    "\n",
    "    # Load the dataset into a data frame\n",
    "    data = pd.read_csv(\"data.txt\", sep=';', header=None).to_numpy()\n",
    "\n",
    "    # Standardize the design space and the objectives\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    data[:, :3] = scaler.fit_transform(data[:, :3])\n",
    "    #data[:, 3:] = preprocessing.MinMaxScaler().fit_transform(data[:, 3:])\n",
    "\n",
    "    # Randomly choose 40 instances to use in GP initialization, sample from the rest\n",
    "    rng = np.random.default_rng()\n",
    "    rng.shuffle(data, axis=0)\n",
    "    gp_split = data[:20]\n",
    "    sample_split = data[20:]\n",
    "\n",
    "    problem_model = OptimizationProblem(dataset=(sample_split[:, :3], sample_split[:, 3:]))\n",
    "\n",
    "    # Specify kernel and mean function for GP prior\n",
    "    kernel_list = [(gpf.kernels.SquaredExponential()) for _ in range(2)]  # lengthscales=[0.1, 0.1, 0.1]\n",
    "    gp = GaussianProcessModel(X=gp_split[:, :3], Y=gp_split[:, 3:], multi=False, periodic=False, m=2,\n",
    "                              kernel_list=kernel_list, verbose=True)\n",
    "\n",
    "    # Adaptive Epsilon PAL algorithm\n",
    "    alg_object = AdaptiveEpsilonPAL(problem_model, epsilon=epsilon, delta=0.15, gp=gp,\n",
    "                                    initial_hypercube=Hypercube(1, (0.5, 0.5, 0.5)))\n",
    "\n",
    "    pareto_set, pareto_set_cells = alg_object.algorithm()\n",
    "\n",
    "    hmax = alg_object.hmax\n",
    "    time_elapsed = alg_object.time_elapsed\n",
    "    tau_eval = alg_object.tau\n",
    "    t_eval = alg_object.t\n",
    "\n",
    "    # Print nodes in the Pareto set\n",
    "    printl(pareto_set)\n",
    "\n",
    "    # Get the center of each node in the Pareto set and plot after observing\n",
    "    pareto_nodes_center = [node.get_center() for node in pareto_set]\n",
    "\n",
    "    # Plot Pareto set\n",
    "    a = np.squeeze(np.array(pareto_nodes_center)).reshape(-1, 3)\n",
    "\n",
    "    y_obs = np.empty((a.shape[0], 2))\n",
    "    i = 0\n",
    "    for row in a:\n",
    "        data_alg = np.array(row)\n",
    "        y = problem_model.observe(data_alg, std=0)\n",
    "        y_obs[i, :] = y\n",
    "        i += 1\n",
    "\n",
    "    # Plot pareto front (two functions)\n",
    "    hotels = pd.DataFrame({\"price\": sample_split[:, 3], \"distance_to_beach\": sample_split[:, 4]})\n",
    "    mask = paretoset(hotels, sense=[\"max\", \"max\"])\n",
    "\n",
    "    # Error metric\n",
    "    p_set = np.hstack((sample_split[:, 3][mask].reshape(-1, 1), sample_split[:, 4][mask].reshape(-1, 1)))\n",
    "    print(p_set)\n",
    "    c = 0\n",
    "    for row in p_set:\n",
    "        # row =\n",
    "        print(row)\n",
    "        a = y_obs - row\n",
    "        print(a)\n",
    "        b = np.linalg.norm(a, axis=1)\n",
    "        print(b)\n",
    "        c += np.min(b)\n",
    "        print(c)\n",
    "        print(\"ended\")\n",
    "    print(p_set.shape[0])\n",
    "\n",
    "    title = \"$\\epsilon = $\" + '%.2f' % epsilon + \", Error = \" + '%.3f' % (c / p_set.shape[0]) + r'$, \\tau $ :' + str(\n",
    "        tau_eval) + \", Time(s) :\" + '%.3f' % time_elapsed\n",
    "\n",
    "    plot_pareto_front(sample_split[:, 3], sample_split[:, 4], mask, y_obs[:, 0], y_obs[:, 1], title=title,\n",
    "                      plotfront=True)\n",
    "    plot_pareto_front(sample_split[:, 3], sample_split[:, 4], mask, y_obs[:, 0], y_obs[:, 1], title=title,\n",
    "                      plotfront=False)\n",
    "\n",
    "    # 2nd\n",
    "    # Get the center of each node in the Pareto set and plot after observing\n",
    "    cell_list = []\n",
    "    for node in pareto_set:\n",
    "        for cell in node.hypercube_list:\n",
    "            cell_list.append(cell)\n",
    "\n",
    "    cells = [hypercube.get_center() for hypercube in cell_list]\n",
    "    # Plot Pareto set\n",
    "    a = np.squeeze(np.array(cells)).reshape(-1, 3)\n",
    "\n",
    "    y_obs = np.empty((a.shape[0], 2))\n",
    "    i = 0\n",
    "    for row in a:\n",
    "        data_alg = np.array(row)\n",
    "        y = problem_model.observe(data_alg, std=0)\n",
    "        y_obs[i, :] = y\n",
    "        i += 1\n",
    "\n",
    "    # Plot pareto front (two functions)\n",
    "    hotels = pd.DataFrame({\"price\": sample_split[:, 3], \"distance_to_beach\": sample_split[:, 4]})\n",
    "    mask = paretoset(hotels, sense=[\"max\", \"max\"])\n",
    "\n",
    "    # Error metric\n",
    "    p_set = np.hstack((sample_split[:, 3][mask].reshape(-1, 1), sample_split[:, 4][mask].reshape(-1, 1)))\n",
    "    print(p_set)\n",
    "    c = 0\n",
    "    for row in p_set:\n",
    "        # row =\n",
    "        print(row)\n",
    "        a = y_obs - row\n",
    "        print(a)\n",
    "        b = np.linalg.norm(a, axis=1)\n",
    "        print(b)\n",
    "        c += np.min(b)\n",
    "        print(c)\n",
    "        print(\"ended\")\n",
    "    print(p_set.shape[0])\n",
    "\n",
    "    title = \"$\\epsilon = $\" + '%.2f' % epsilon + \", Error = \" + '%.3f' % (c / p_set.shape[0]) + r'$, \\tau $ :' + str(\n",
    "        tau_eval) + \", Time(s) :\" + '%.3f' % time_elapsed\n",
    "\n",
    "    plot_pareto_front(sample_split[:, 3], sample_split[:, 4], mask, y_obs[:, 0], y_obs[:, 1], title=title,\n",
    "                      plotfront=True)\n",
    "    plot_pareto_front(sample_split[:, 3], sample_split[:, 4], mask, y_obs[:, 0], y_obs[:, 1], title=title,\n",
    "                      plotfront=False)\n",
    "    return tau_eval, c / p_set.shape[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}